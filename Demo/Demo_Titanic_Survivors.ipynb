{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxVm8weFe9-N"
      },
      "outputs": [],
      "source": [
        "# https://blog.socialcops.com/engineering/machine-learning-python/\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (15.0, 8.0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/davewadestein/Gap-Python-2025/refs/heads/main/Data/titanic3.xls"
      ],
      "metadata": {
        "id": "NIDi8yrwiNct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PirkyjTGe9-O"
      },
      "source": [
        "# Let's read in the Titanic data for a deeper analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ucx00OmXe9-O"
      },
      "outputs": [],
      "source": [
        "data = pd.read_excel('titanic3.xls', 'titanic3', index_col=None, na_values=['NA'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9rlnuaOe9-P"
      },
      "source": [
        "## Legend\n",
        "* pclass = Passenger Class (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
        "* survival (0 = No; 1 = Yes)\n",
        "* sibsp = number of Siblings/Spouses Aboard\n",
        "* parch = number of Parents/Children Aboard\n",
        "* ticket = ticket Number\n",
        "* embarked (from...C = Cherbourg; Q = Queenstown; S = Southampton)\n",
        "* boat = Lifeboat ID\n",
        "* body = ID Number\n",
        "* home.dest = Home/Destination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAs4jfr4e9-P"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdk7lE8Ee9-P"
      },
      "source": [
        "### These columns are unlikely to be meaningful and have several missing values so we'll drop them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJpBCeNle9-P"
      },
      "outputs": [],
      "source": [
        "data = data.drop(['boat', 'ticket', 'cabin', 'body'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BvRGraz0e9-P"
      },
      "source": [
        "### We can get a quick summary of how many people survived."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfpo4HMye9-Q"
      },
      "outputs": [],
      "source": [
        "data['survived'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2l96VNGOe9-Q"
      },
      "source": [
        "### Because we encode survival as '1', finding the mean will give us a survival percentage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4yLVQ7ge9-Q"
      },
      "outputs": [],
      "source": [
        "data['survived'].mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkDnc0Ume9-Q"
      },
      "source": [
        "### If we group by class and then compute the mean, what does this reveal?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sd4kujpRe9-Q"
      },
      "outputs": [],
      "source": [
        "data.groupby('pclass').mean(numeric_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQHdjYzOe9-Q"
      },
      "source": [
        "### Pandas groupby() method essentially creates a bunch of dataframes in which the all the columns match the various values of the grouping variables...\n",
        "* we can see this by looking at the __`groups`__ attribute\n",
        "* each grouping contains the rows of the dataframe\n",
        "* so in the example below, rows 0, 2, 4, 6, 8, etc. are the females in 1st class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Tmx01uYe9-Q"
      },
      "outputs": [],
      "source": [
        "data.groupby(['pclass', 'sex']).groups"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LD_eM3KWe9-Q"
      },
      "source": [
        "### If we group by class and gender and compute the mean, what does this tell us about the \"Women\" part of \"Women and children first?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7H5BCfM9e9-Q"
      },
      "outputs": [],
      "source": [
        "class_gender_grouping = data.groupby(['pclass', 'sex']).mean(numeric_only=True)\n",
        "class_gender_grouping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cM5SNWDe9-Q"
      },
      "source": [
        "### Let's render it as a bar chart to make it clear..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dB4wqp_3e9-Q"
      },
      "outputs": [],
      "source": [
        "class_gender_grouping.survived.plot.bar();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL-9827ze9-Q"
      },
      "source": [
        "### If we investigate the passengers by age, we can investigate the \"Children\" part of \"Women and children first\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aZBMFA_e9-Q"
      },
      "outputs": [],
      "source": [
        "group_by_age = pd.cut(data.age, np.arange(0, 90, 10))\n",
        "age_grouping = data.groupby(group_by_age, observed=False)['survived'].mean(numeric_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEq6-9SXe9-R"
      },
      "outputs": [],
      "source": [
        "age_grouping.plot.bar();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4etTIiMe9-R"
      },
      "outputs": [],
      "source": [
        "group_by_age.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVo5ClXBe9-R"
      },
      "source": [
        "### We have a fair amount of missing values (e.g., __`age`__, __`home.dest`__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZS8nh9Ate9-R"
      },
      "outputs": [],
      "source": [
        "data.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi7lk8ble9-R"
      },
      "source": [
        "### We can fill in the missing age values with average values. Is this a good strategy for this data? What could we exploit to make a better go of it? (Hint: Look at the class breakdowns above)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQuPrxvhe9-R"
      },
      "outputs": [],
      "source": [
        "data = data.fillna(data.mean(numeric_only=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZwmQXNOe9-R"
      },
      "source": [
        "### Now we are basically missing home/destination data and a few embarked results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d06Dq33e9-R"
      },
      "outputs": [],
      "source": [
        "data.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMsvl-FYe9-R"
      },
      "source": [
        "### With only two results missing embarked data, we can probably just drop those samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7uLNLfHe9-R"
      },
      "outputs": [],
      "source": [
        "data[data['embarked'].isnull()]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "el3qV_Exe9-R"
      },
      "source": [
        "### There are a substantial number of missing home/destination values. We don't know if that is an important feature, but we'd lose a lot of data if we throw those samples away, so let's fill it in with placeholders for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7Nv3XTZe9-R"
      },
      "outputs": [],
      "source": [
        "data[\"home.dest\"] = data[\"home.dest\"].fillna(\"NA\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv7iy7GTe9-R"
      },
      "source": [
        "### Now with only the two embarked rows missing, we are in good shape, so let's drop those and then move on."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guHQrNZ0e9-R"
      },
      "outputs": [],
      "source": [
        "data.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtVIMoO-e9-R"
      },
      "outputs": [],
      "source": [
        "data = data.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0CNW12je9-R"
      },
      "outputs": [],
      "source": [
        "data.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbGgOtbie9-R"
      },
      "source": [
        "### We are going to turn categorical data (__`sex`__ and __`embarked`__) into numbered values using a Sci-Kit Learn __`LabelEncoder`__."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_8C62mee9-R"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets, model_selection, tree, preprocessing, metrics\n",
        "import sklearn.ensemble as ske"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iOavXJACe9-S"
      },
      "outputs": [],
      "source": [
        "def preprocess_titanic_df(df):\n",
        "    processed_df = df.copy()\n",
        "    le = preprocessing.LabelEncoder()\n",
        "\n",
        "    processed_df.sex = le.fit_transform(processed_df.sex)\n",
        "    processed_df.embarked = le.fit_transform(processed_df.embarked)\n",
        "    processed_df = processed_df.drop(['name', 'home.dest'],axis=1)\n",
        "\n",
        "    return processed_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5wpdlXIe9-S"
      },
      "source": [
        "### We preprocess our data and then verify that everything is suitable for a learning activity now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7fSoYXFe9-S"
      },
      "outputs": [],
      "source": [
        "processed_df = preprocess_titanic_df(data)\n",
        "processed_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u9m45ime9-S"
      },
      "source": [
        "### The survival data is going to be our target so we drop it from the feature matrix and set up the target matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH9uZC3te9-S"
      },
      "outputs": [],
      "source": [
        "X = processed_df.drop(['survived'], axis=1)\n",
        "y = processed_df['survived']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4_2ZkHse9-S"
      },
      "source": [
        "### We now split our data into training and test data, create a DecisionTreeClassifier and then see how we do on predictions on survival."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wCXC1Xfe9-S"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgnJ_utze9-S"
      },
      "outputs": [],
      "source": [
        "clf_dt = tree.DecisionTreeClassifier(max_depth=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QlR1zS1Me9-S"
      },
      "outputs": [],
      "source": [
        "clf_dt.fit(X_train, y_train)\n",
        "clf_dt.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTct9wGze9-S"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "export_graphviz(clf_dt, out_file=\"titanic.dot\",\n",
        "               feature_names='pclass sex age sibsp parch fare embarked'.split(),\n",
        "               class_names='perished survived'.split(),\n",
        "               rounded=True,filled=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mM2cOdmIe9-S"
      },
      "outputs": [],
      "source": [
        "!dot -Tpng titanic.dot -o titanic.png\n",
        "from IPython.display import Image\n",
        "Image('titanic.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou7UM9Fte9-S"
      },
      "source": [
        "### Shuffling the data can sometimes improve our results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaUofQa4e9-S"
      },
      "outputs": [],
      "source": [
        "shuffle_validator = model_selection.ShuffleSplit(len(X), test_size=0.2, random_state=0)\n",
        "\n",
        "def test_classifier(clf):\n",
        "    scores = model_selection.cross_val_score(clf, X, y, cv=shuffle_validator)\n",
        "    print(\"Accuracy: %0.4f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPoDINeKe9-S"
      },
      "outputs": [],
      "source": [
        "test_classifier(clf_dt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52Wgnk_me9-S"
      },
      "source": [
        "### A RandomForestClassifier often does better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wj-C8ePye9-S"
      },
      "outputs": [],
      "source": [
        "clf_rf = ske.RandomForestClassifier(n_estimators=50)\n",
        "test_classifier(clf_rf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEOR9rp-e9-T"
      },
      "source": [
        "### Other classifiers might do even better..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSRxPd5Ke9-T"
      },
      "outputs": [],
      "source": [
        "clf_gb = ske.GradientBoostingClassifier(n_estimators=50)\n",
        "test_classifier(clf_gb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d8zKVIspphYa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Fhh4FmKe9-T"
      },
      "source": [
        "### Now we want to make a specific point, so we'll grab the first twenty rows of each passenger class from our raw data, clean them up and use them as our test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UCaPWDite9-T"
      },
      "outputs": [],
      "source": [
        "passengers_set_1 = data[data.pclass == 1].iloc[:20,:].copy()\n",
        "passengers_set_2 = data[data.pclass == 2].iloc[:20,:].copy()\n",
        "passengers_set_3 = data[data.pclass == 3].iloc[:20,:].copy()\n",
        "passenger_set = pd.concat([passengers_set_1, passengers_set_2, passengers_set_3])\n",
        "testing_set = preprocess_titanic_df(passenger_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oN5zJOute9-T"
      },
      "source": [
        "### Normally you wouldn't train and test on the same data, but we're trying to make a point (and this is a closed system–we're not going to use our model on new, unseen data!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_v7hqiOOe9-T"
      },
      "outputs": [],
      "source": [
        "training_set = pd.concat([data, passenger_set]).drop_duplicates(keep=False)\n",
        "training_set = preprocess_titanic_df(training_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3-bvltce9-T"
      },
      "outputs": [],
      "source": [
        "X = training_set.drop(['survived'], axis=1).values\n",
        "y = training_set['survived'].values\n",
        "X_test = testing_set.drop(['survived'], axis=1).values\n",
        "y_test = testing_set['survived'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUs1N_iSe9-T"
      },
      "outputs": [],
      "source": [
        "clf_rf = ske.RandomForestClassifier(n_estimators=50)\n",
        "clf_rf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gO9DqRTe9-T"
      },
      "outputs": [],
      "source": [
        "prediction = clf_rf.predict(X_test)\n",
        "prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqvsLLDee9-T"
      },
      "source": [
        "### Because this is historical data, we can compare predictions to what actually happened.\n",
        "* Models are not destiny!\n",
        "* ...some of the people our model thought would survive didn't and some of the people it thought wouldn't did."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O75wiRK2e9-T"
      },
      "outputs": [],
      "source": [
        "passenger_set[passenger_set.survived != prediction]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLPaemc1e9-T"
      },
      "outputs": [],
      "source": [
        "clf_rf.score(X_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}